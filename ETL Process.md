# Data-Pipeline

## 1) Data source: 

Tables from AWS (OLTP):

![image](https://github.com/Gonzalodl88/Data-Pipeline/assets/56099577/fc318697-1302-476e-bca4-170c6ab8f9c1)

## 2) ETL Process: 

Performed by the Alterix software, in this part of the process we are going to Extract information from the data sources, then we will Transform it, and finally Load it into our data warehouse.
  
![image](https://github.com/Gonzalodl88/Data-Pipeline/assets/56099577/b634a27b-4987-4465-ab55-97e718de82ed)
 
![image](https://github.com/Gonzalodl88/Data-Pipeline/assets/56099577/defa30b9-3166-4ef6-8ad5-de823407d872)
    
![image](https://github.com/Gonzalodl88/Data-Pipeline/assets/56099577/c8f9224c-6632-43ad-8987-985c4ca982ca)

![image](https://github.com/Gonzalodl88/Data-Pipeline/assets/56099577/a47fe6ed-a3df-4dba-a6ea-0a4018ea0cf8)

![image](https://github.com/Gonzalodl88/Data-Pipeline/assets/56099577/b3f0b9f7-3c70-451e-b423-c8dd15d13c2e)

## 3) Data warehouse:

Process performed in MySQL, a diagram is designed and loaded with the information mentioned in point 2.

![image](https://github.com/Gonzalodl88/Data-Pipeline/assets/56099577/56ed1d3d-a50e-4562-855c-2637d958533e)

## 4) Visualization: 

PowerBI was used for visualization, you can see the dashboard at the following link:

https://app.powerbi.com/view?r=eyJrIjoiOGI0MjhiNmQtMTk0Ni00NjFiLTg2ZGYtYzU5MzhlMGIxNTZhIiwidCI6ImE2ZDk4MWQzLTdiMWUtNDdiYy04MzRiLTkzODgxOTRiMWM4MCJ9
